# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк, 8 числовых признаков)
- Признаки: Все числовые (float).
- Пропуски: нет.
- "Подлости" датасета: Признаки имеют разные шкалы, присутствует шум. Требуется обязательное масштабирование.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк, 3 числовых признака)
- Признаки: Числовые (float).
- Пропуски: нет.
- "Подлости" датасета: Нелинейная структура кластеров (формы, отличные от шаров), наличие шумового признака `z_noise`.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000 строк, 30 числовых + 2 категориальных)
- Признаки: Смешанные (float и категориальные символы).
- Пропуски: Присутствуют в числовых данных.
- "Подлости" датасета: Высокая размерность, необходимость обработки пропусков и кодирования категорий (OHE).

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг:
  - Для числовых признаков (DS-01, DS-02, DS-04): Использовался `StandardScaler` для приведения признаков к единому масштабу (`mean=0`, `std=1`). Для DS-04 добавлена импутация пропусков (`SimpleImputer` strategy='mean').
  - Для категориальных признаков (DS-04): Применен `OneHotEncoder` с `handle_unknown='ignore'`.
  - Все шаги объединены в `Pipeline` и `ColumnTransformer`.
  
- Поиск гиперпараметров:
  - KMeans: перебор $k$ в диапазоне от 2 до 10.
  - DBSCAN: перебор `eps` (сетка [0.1, 0.2, 0.3, 0.5, ...]) при фиксированном `min_samples` (эвристика $\approx 2 \cdot dim$).
  - Agglomerative: перебор $k$ и вариантов `linkage` ('ward', 'average').
  - Выбор лучшего осуществлялся на основе максимизации `silhouette_score` при адекватной интерпретируемости (отсутствие единственного гигантского кластера).

- Метрики:
  - Основные: Silhouette Score, Davies-Bouldin, Calinski-Harabasz.
  - Для DBSCAN: Метрики считались только на Core-точках (исключая шум label = -1), также фиксировалась доля шума.

- Визуализация: - PCA(2D) для итоговых кластеров.
  - Графики зависимости Silhouette от гиперпараметров ($k$ или $eps$).

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

- Dataset A
  - KMeans (подбор $k$, `n_init=10`)
  - DBSCAN (подбор `eps`, `min_samples=16`)
- Dataset B
  - KMeans (подбор $k$) — для демонстрации неспособности разделить нелинейность.
  - DBSCAN (подбор `eps`, `min_samples=5`) — для выявления форм.
- Dataset C
  - KMeans (подбор $k$)
  - AgglomerativeClustering (подбор $k$, comparison of `ward` vs `average` linkage).

Опционально: третий метод / дополнительные варианты параметров.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: **KMeans (k=2)**
- Метрики:
  - Silhouette: **0.5216395622404242**
- Коротко: Масштабирование позволило алгоритмам корректно определить расстояние. Решение выглядит стабильным, кластеры хорошо разделены визуально на PCA.

### 4.2 Dataset B

- Лучший метод и параметры: **DBSCAN (eps=0.3, min_samples=5)**
- Метрики:
  - DBSCAN
- Если был DBSCAN: доля шума **0.072375%**.
- Коротко: KMeans разбил данные на выпуклые области, разрезав естественные формы. DBSCAN корректно выделил нелинейные структуры, отбросив выбросы в шум.

### 4.3 Dataset C

- Лучший метод и параметры: **Agglomerative/KMeans (k=5)**
- Метрики:
  - Silhouette: **0.4480173757704073**
- Коротко: Из-за высокой размерности и смешанных признаков плотностные методы (DBSCAN) настраивать сложно. Agglomerative Clustering с linkage='ward' показал хорошие результаты на предобработанных данных (OHE).

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается": На Dataset 02. KMeans пытается минимизировать дисперсию внутри кластера, что приводит к созданию сферических границ. На данных в форме "полумесяцев" это приводит к некорректному разбиению.
- Где выигрывают другие: DBSCAN идеально сработал на Dataset 02 благодаря подходу, основанному на плотности, а не на центроидах. Agglomerative Clustering позволил гибко подойти к Dataset 04.
- Влияние препроцессинга: Без `StandardScaler` на Dataset 01 признаки с большими значениями доминировали бы при расчете расстояний. На Dataset 04 `OneHotEncoder` был критически важен для включения категориальных данных в метрические алгоритмы.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка: 5 запусков KMeans на Dataset 01 с разными `random_state` (seed).
- Результат: Средний ARI (Adjusted Rand Index) составил 1.0.
- Вывод: Алгоритм устойчив. При наличии явной кластерной структуры и достаточном количестве итераций (`n_init`), KMeans сходится к одному и тому же решению независимо от инициализации.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через анализ профилей (центроидов) и визуализацию PCA.
- На Dataset 01 кластеры различаются по магнитуде значений (после склейки шкал). На Dataset 04 кластеры, вероятно, группируются по комбинации категориальных признаков (`cat_a`) и числовых паттернов.

## 6. Conclusion

1. Масштабирование обязательно: Distance-based методы (KMeans, DBSCAN) не работают корректно без `StandardScaler`, если признаки имеют разный разброс.
2. Геометрия имеет значение: Для нелинейных данных (дуги, кольца) KMeans не подходит; следует использовать DBSCAN или спектральную кластеризацию.
3. Проклятие размерности: На Dataset 04 (30+ признаков) выбор `eps` для DBSCAN становится сложной задачей из-за разреженности пространства; иерархическая кластеризация или KMeans здесь проще в настройке.
4. Метрики не абсолютны: Высокий Silhouette не всегда означает "правильное" разбиение (особенно на невыпуклых данных, где Silhouette "любит" шары). Визуализация и логика важнее слепой погони за цифрами.
5. DBSCAN и шум: Важно исключать шумовые точки (`-1`) при расчете метрик качества, иначе показатели будут сильно занижены.