# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000, 39) — id + 37 признаков + target
- Целевая переменная: `target` (Бинарная классификация: 0 и 1. Распределение умеренное, приблизительно 74/26).
- Признаки: 35 анонимизированных признаков f01-f35 и 2 признака x_int_1, x_int_2. Все признаки числовые (float).

## 2. Protocol

- Разбиение: train/test в пропорции 80/20, random_state=42 со стратификацией по target
- Подбор: GridSearchCV на 5 фолдах (CV) проводился только на тренировочной выборке
- Метрики: Accuracy (общая точность), F1-score (баланс precision/recall) и ROC-AUC (качество ранжирования вероятностей)

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier: Базовая модель, всегда предсказывающая наиболее частый класс.
- LogisticRegression: Линейный baseline с предварительным масштабированием признаков (StandardScaler).
- DecisionTreeClassifier: Дерево решений. Подбирались max_depth и min_samples_leaf для борьбы с переобучением.
- RandomForestClassifier: Ансамбль деревьев (bagging). Подбиралось количество деревьев и глубина.
- Один boosting: Последовательный ансамбль (boosting). Подбирались темп обучения (learning_rate) и количество итераций.

## 4. Results

Модель,Accuracy,F1,ROC-AUC
Dummy,0.74,0.00,0.50
LogisticRegression,0.81,0.56,0.80
DecisionTree,0.82,0.61,0.83
RandomForest,0.89,0.76,0.93
HistGradientBoosting,0.90,0.79,0.92

Победитель: RandomForest. Модель показала лучший ROC-AUC, так как она эффективно справляется с нелинейными взаимодействиями признаков, которые заложены в датасете №2.

## 5. Analysis

- Устойчивость: При изменении random_state метрики ансамблей (RF, Boosting) колеблются незначительно (в пределах 1-2%), что говорит об их стабильности по сравнению с одиночным деревом.
- Ошибки: Судя по матрице ошибок, модель иногда путает классы в зонах сильного перекрытия, что ожидаемо для "сложного" датасета с шумом.
- Интерпретация: Permutation importance выявил, что признаки x_int_1 и x_int_2 имеют высокий вес, что подтверждает наличие важных взаимодействий в данных.

## 6. Conclusion

1. Ансамбли (Random Forest и Boosting) значительно превосходят одиночные деревья и линейные модели на данных со сложной структурой.
2. Контроль сложности дерева (глубина, min samples) критически важен, иначе модель мгновенно переобучается под шум.
3. Честный ML-эксперимент (фиксация seed, CV только на train) — единственный способ получить достоверную оценку качества модели
